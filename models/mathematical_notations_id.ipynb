{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "X_shape: torch.Size([64, 1, 28, 28])\n",
      "y_shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "  print(f\"Batch {batch}\")\n",
    "  print(f\"X_shape: {X.shape}\")\n",
    "  print(f\"y_shape: {y.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.seq = nn.Sequential(\n",
    "        nn.Linear(28 * 28, 256), # Input layer\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10) # Output layer\n",
    "    )\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = self.flatten(X)\n",
    "    return self.seq(X)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # print(f\"Batch: {batch}\")\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.202591  [   64/60000]\n",
      "loss: 0.308743  [ 6464/60000]\n",
      "loss: 0.211863  [12864/60000]\n",
      "loss: 0.341256  [19264/60000]\n",
      "loss: 0.284628  [25664/60000]\n",
      "loss: 0.322744  [32064/60000]\n",
      "loss: 0.314107  [38464/60000]\n",
      "loss: 0.415893  [44864/60000]\n",
      "loss: 0.406375  [51264/60000]\n",
      "loss: 0.355546  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.370295 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.200230  [   64/60000]\n",
      "loss: 0.304949  [ 6464/60000]\n",
      "loss: 0.209893  [12864/60000]\n",
      "loss: 0.336565  [19264/60000]\n",
      "loss: 0.283119  [25664/60000]\n",
      "loss: 0.323610  [32064/60000]\n",
      "loss: 0.311492  [38464/60000]\n",
      "loss: 0.411019  [44864/60000]\n",
      "loss: 0.399190  [51264/60000]\n",
      "loss: 0.354578  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.368442 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.199143  [   64/60000]\n",
      "loss: 0.300753  [ 6464/60000]\n",
      "loss: 0.207541  [12864/60000]\n",
      "loss: 0.332614  [19264/60000]\n",
      "loss: 0.281033  [25664/60000]\n",
      "loss: 0.317786  [32064/60000]\n",
      "loss: 0.310782  [38464/60000]\n",
      "loss: 0.403851  [44864/60000]\n",
      "loss: 0.394968  [51264/60000]\n",
      "loss: 0.352902  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.366514 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.198135  [   64/60000]\n",
      "loss: 0.297687  [ 6464/60000]\n",
      "loss: 0.204991  [12864/60000]\n",
      "loss: 0.328541  [19264/60000]\n",
      "loss: 0.280418  [25664/60000]\n",
      "loss: 0.314750  [32064/60000]\n",
      "loss: 0.306616  [38464/60000]\n",
      "loss: 0.397943  [44864/60000]\n",
      "loss: 0.391200  [51264/60000]\n",
      "loss: 0.351683  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.363787 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.194166  [   64/60000]\n",
      "loss: 0.294223  [ 6464/60000]\n",
      "loss: 0.202360  [12864/60000]\n",
      "loss: 0.324168  [19264/60000]\n",
      "loss: 0.279799  [25664/60000]\n",
      "loss: 0.312100  [32064/60000]\n",
      "loss: 0.303789  [38464/60000]\n",
      "loss: 0.392616  [44864/60000]\n",
      "loss: 0.386029  [51264/60000]\n",
      "loss: 0.350427  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.361226 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.191066  [   64/60000]\n",
      "loss: 0.291814  [ 6464/60000]\n",
      "loss: 0.200688  [12864/60000]\n",
      "loss: 0.320805  [19264/60000]\n",
      "loss: 0.279791  [25664/60000]\n",
      "loss: 0.309130  [32064/60000]\n",
      "loss: 0.299317  [38464/60000]\n",
      "loss: 0.388379  [44864/60000]\n",
      "loss: 0.383543  [51264/60000]\n",
      "loss: 0.349122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.359315 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.189156  [   64/60000]\n",
      "loss: 0.289103  [ 6464/60000]\n",
      "loss: 0.199165  [12864/60000]\n",
      "loss: 0.316488  [19264/60000]\n",
      "loss: 0.278130  [25664/60000]\n",
      "loss: 0.305678  [32064/60000]\n",
      "loss: 0.297394  [38464/60000]\n",
      "loss: 0.383855  [44864/60000]\n",
      "loss: 0.379289  [51264/60000]\n",
      "loss: 0.346907  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.358673 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.190707  [   64/60000]\n",
      "loss: 0.286974  [ 6464/60000]\n",
      "loss: 0.198650  [12864/60000]\n",
      "loss: 0.313702  [19264/60000]\n",
      "loss: 0.277138  [25664/60000]\n",
      "loss: 0.304070  [32064/60000]\n",
      "loss: 0.293264  [38464/60000]\n",
      "loss: 0.378811  [44864/60000]\n",
      "loss: 0.374492  [51264/60000]\n",
      "loss: 0.344452  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.357753 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.190173  [   64/60000]\n",
      "loss: 0.283640  [ 6464/60000]\n",
      "loss: 0.194915  [12864/60000]\n",
      "loss: 0.309456  [19264/60000]\n",
      "loss: 0.277123  [25664/60000]\n",
      "loss: 0.298749  [32064/60000]\n",
      "loss: 0.290117  [38464/60000]\n",
      "loss: 0.372813  [44864/60000]\n",
      "loss: 0.372060  [51264/60000]\n",
      "loss: 0.344892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355923 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.190318  [   64/60000]\n",
      "loss: 0.281733  [ 6464/60000]\n",
      "loss: 0.192782  [12864/60000]\n",
      "loss: 0.306053  [19264/60000]\n",
      "loss: 0.276263  [25664/60000]\n",
      "loss: 0.295501  [32064/60000]\n",
      "loss: 0.286615  [38464/60000]\n",
      "loss: 0.366697  [44864/60000]\n",
      "loss: 0.367140  [51264/60000]\n",
      "loss: 0.345195  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355273 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.189344  [   64/60000]\n",
      "loss: 0.279670  [ 6464/60000]\n",
      "loss: 0.189898  [12864/60000]\n",
      "loss: 0.303109  [19264/60000]\n",
      "loss: 0.276223  [25664/60000]\n",
      "loss: 0.291939  [32064/60000]\n",
      "loss: 0.282845  [38464/60000]\n",
      "loss: 0.361642  [44864/60000]\n",
      "loss: 0.363582  [51264/60000]\n",
      "loss: 0.343244  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.354153 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.188027  [   64/60000]\n",
      "loss: 0.277349  [ 6464/60000]\n",
      "loss: 0.188264  [12864/60000]\n",
      "loss: 0.299495  [19264/60000]\n",
      "loss: 0.275559  [25664/60000]\n",
      "loss: 0.289170  [32064/60000]\n",
      "loss: 0.277685  [38464/60000]\n",
      "loss: 0.357175  [44864/60000]\n",
      "loss: 0.358778  [51264/60000]\n",
      "loss: 0.340932  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.352222 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.186506  [   64/60000]\n",
      "loss: 0.276047  [ 6464/60000]\n",
      "loss: 0.185959  [12864/60000]\n",
      "loss: 0.296420  [19264/60000]\n",
      "loss: 0.275707  [25664/60000]\n",
      "loss: 0.286319  [32064/60000]\n",
      "loss: 0.275433  [38464/60000]\n",
      "loss: 0.353693  [44864/60000]\n",
      "loss: 0.355814  [51264/60000]\n",
      "loss: 0.339397  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.350193 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.183811  [   64/60000]\n",
      "loss: 0.272955  [ 6464/60000]\n",
      "loss: 0.183276  [12864/60000]\n",
      "loss: 0.293000  [19264/60000]\n",
      "loss: 0.275299  [25664/60000]\n",
      "loss: 0.285266  [32064/60000]\n",
      "loss: 0.270936  [38464/60000]\n",
      "loss: 0.350442  [44864/60000]\n",
      "loss: 0.352462  [51264/60000]\n",
      "loss: 0.339622  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.348662 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.182968  [   64/60000]\n",
      "loss: 0.270553  [ 6464/60000]\n",
      "loss: 0.180682  [12864/60000]\n",
      "loss: 0.290388  [19264/60000]\n",
      "loss: 0.275830  [25664/60000]\n",
      "loss: 0.281352  [32064/60000]\n",
      "loss: 0.267187  [38464/60000]\n",
      "loss: 0.346381  [44864/60000]\n",
      "loss: 0.348697  [51264/60000]\n",
      "loss: 0.337914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347278 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.180979  [   64/60000]\n",
      "loss: 0.267379  [ 6464/60000]\n",
      "loss: 0.179840  [12864/60000]\n",
      "loss: 0.285792  [19264/60000]\n",
      "loss: 0.275792  [25664/60000]\n",
      "loss: 0.278393  [32064/60000]\n",
      "loss: 0.265112  [38464/60000]\n",
      "loss: 0.340950  [44864/60000]\n",
      "loss: 0.346496  [51264/60000]\n",
      "loss: 0.333936  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.347491 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.181244  [   64/60000]\n",
      "loss: 0.265997  [ 6464/60000]\n",
      "loss: 0.177707  [12864/60000]\n",
      "loss: 0.283048  [19264/60000]\n",
      "loss: 0.275005  [25664/60000]\n",
      "loss: 0.277116  [32064/60000]\n",
      "loss: 0.261464  [38464/60000]\n",
      "loss: 0.338091  [44864/60000]\n",
      "loss: 0.343005  [51264/60000]\n",
      "loss: 0.333451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.345826 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.178390  [   64/60000]\n",
      "loss: 0.261606  [ 6464/60000]\n",
      "loss: 0.174424  [12864/60000]\n",
      "loss: 0.280808  [19264/60000]\n",
      "loss: 0.274592  [25664/60000]\n",
      "loss: 0.275229  [32064/60000]\n",
      "loss: 0.257832  [38464/60000]\n",
      "loss: 0.334152  [44864/60000]\n",
      "loss: 0.339812  [51264/60000]\n",
      "loss: 0.330873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.344503 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.176773  [   64/60000]\n",
      "loss: 0.259562  [ 6464/60000]\n",
      "loss: 0.172149  [12864/60000]\n",
      "loss: 0.277352  [19264/60000]\n",
      "loss: 0.274486  [25664/60000]\n",
      "loss: 0.272262  [32064/60000]\n",
      "loss: 0.254538  [38464/60000]\n",
      "loss: 0.329407  [44864/60000]\n",
      "loss: 0.337211  [51264/60000]\n",
      "loss: 0.328082  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342290 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.172740  [   64/60000]\n",
      "loss: 0.258178  [ 6464/60000]\n",
      "loss: 0.169503  [12864/60000]\n",
      "loss: 0.273882  [19264/60000]\n",
      "loss: 0.274630  [25664/60000]\n",
      "loss: 0.270171  [32064/60000]\n",
      "loss: 0.252161  [38464/60000]\n",
      "loss: 0.325574  [44864/60000]\n",
      "loss: 0.336139  [51264/60000]\n",
      "loss: 0.326336  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.341944 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.173030  [   64/60000]\n",
      "loss: 0.255428  [ 6464/60000]\n",
      "loss: 0.166911  [12864/60000]\n",
      "loss: 0.270393  [19264/60000]\n",
      "loss: 0.274906  [25664/60000]\n",
      "loss: 0.266793  [32064/60000]\n",
      "loss: 0.248393  [38464/60000]\n",
      "loss: 0.321309  [44864/60000]\n",
      "loss: 0.332088  [51264/60000]\n",
      "loss: 0.324037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340747 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.172602  [   64/60000]\n",
      "loss: 0.253060  [ 6464/60000]\n",
      "loss: 0.165817  [12864/60000]\n",
      "loss: 0.267201  [19264/60000]\n",
      "loss: 0.273449  [25664/60000]\n",
      "loss: 0.265075  [32064/60000]\n",
      "loss: 0.244897  [38464/60000]\n",
      "loss: 0.316957  [44864/60000]\n",
      "loss: 0.329151  [51264/60000]\n",
      "loss: 0.321659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340267 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.171762  [   64/60000]\n",
      "loss: 0.251987  [ 6464/60000]\n",
      "loss: 0.165144  [12864/60000]\n",
      "loss: 0.263391  [19264/60000]\n",
      "loss: 0.274501  [25664/60000]\n",
      "loss: 0.263484  [32064/60000]\n",
      "loss: 0.240226  [38464/60000]\n",
      "loss: 0.311633  [44864/60000]\n",
      "loss: 0.327034  [51264/60000]\n",
      "loss: 0.319257  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.338801 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.171729  [   64/60000]\n",
      "loss: 0.250600  [ 6464/60000]\n",
      "loss: 0.162230  [12864/60000]\n",
      "loss: 0.260619  [19264/60000]\n",
      "loss: 0.273780  [25664/60000]\n",
      "loss: 0.261746  [32064/60000]\n",
      "loss: 0.238835  [38464/60000]\n",
      "loss: 0.305901  [44864/60000]\n",
      "loss: 0.326868  [51264/60000]\n",
      "loss: 0.317014  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.339018 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.171243  [   64/60000]\n",
      "loss: 0.249971  [ 6464/60000]\n",
      "loss: 0.160395  [12864/60000]\n",
      "loss: 0.257420  [19264/60000]\n",
      "loss: 0.273336  [25664/60000]\n",
      "loss: 0.258233  [32064/60000]\n",
      "loss: 0.235128  [38464/60000]\n",
      "loss: 0.303738  [44864/60000]\n",
      "loss: 0.322734  [51264/60000]\n",
      "loss: 0.316618  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336948 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.169501  [   64/60000]\n",
      "loss: 0.247649  [ 6464/60000]\n",
      "loss: 0.158641  [12864/60000]\n",
      "loss: 0.254230  [19264/60000]\n",
      "loss: 0.274196  [25664/60000]\n",
      "loss: 0.255430  [32064/60000]\n",
      "loss: 0.233669  [38464/60000]\n",
      "loss: 0.299735  [44864/60000]\n",
      "loss: 0.320229  [51264/60000]\n",
      "loss: 0.314864  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.336884 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.170590  [   64/60000]\n",
      "loss: 0.246682  [ 6464/60000]\n",
      "loss: 0.156699  [12864/60000]\n",
      "loss: 0.250806  [19264/60000]\n",
      "loss: 0.275231  [25664/60000]\n",
      "loss: 0.252688  [32064/60000]\n",
      "loss: 0.230560  [38464/60000]\n",
      "loss: 0.295267  [44864/60000]\n",
      "loss: 0.317876  [51264/60000]\n",
      "loss: 0.314921  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.335591 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.168062  [   64/60000]\n",
      "loss: 0.244205  [ 6464/60000]\n",
      "loss: 0.155313  [12864/60000]\n",
      "loss: 0.249725  [19264/60000]\n",
      "loss: 0.273396  [25664/60000]\n",
      "loss: 0.248207  [32064/60000]\n",
      "loss: 0.227670  [38464/60000]\n",
      "loss: 0.292054  [44864/60000]\n",
      "loss: 0.315645  [51264/60000]\n",
      "loss: 0.311133  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335449 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.168492  [   64/60000]\n",
      "loss: 0.241733  [ 6464/60000]\n",
      "loss: 0.153160  [12864/60000]\n",
      "loss: 0.247380  [19264/60000]\n",
      "loss: 0.275300  [25664/60000]\n",
      "loss: 0.246913  [32064/60000]\n",
      "loss: 0.224313  [38464/60000]\n",
      "loss: 0.286404  [44864/60000]\n",
      "loss: 0.313551  [51264/60000]\n",
      "loss: 0.311173  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334891 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.168931  [   64/60000]\n",
      "loss: 0.239046  [ 6464/60000]\n",
      "loss: 0.151628  [12864/60000]\n",
      "loss: 0.244956  [19264/60000]\n",
      "loss: 0.274106  [25664/60000]\n",
      "loss: 0.244757  [32064/60000]\n",
      "loss: 0.222828  [38464/60000]\n",
      "loss: 0.281642  [44864/60000]\n",
      "loss: 0.310270  [51264/60000]\n",
      "loss: 0.307956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335807 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.169479  [   64/60000]\n",
      "loss: 0.238132  [ 6464/60000]\n",
      "loss: 0.150345  [12864/60000]\n",
      "loss: 0.242596  [19264/60000]\n",
      "loss: 0.274992  [25664/60000]\n",
      "loss: 0.242385  [32064/60000]\n",
      "loss: 0.219300  [38464/60000]\n",
      "loss: 0.276573  [44864/60000]\n",
      "loss: 0.304238  [51264/60000]\n",
      "loss: 0.305502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335378 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.168923  [   64/60000]\n",
      "loss: 0.237027  [ 6464/60000]\n",
      "loss: 0.147969  [12864/60000]\n",
      "loss: 0.238283  [19264/60000]\n",
      "loss: 0.275406  [25664/60000]\n",
      "loss: 0.240924  [32064/60000]\n",
      "loss: 0.217461  [38464/60000]\n",
      "loss: 0.274806  [44864/60000]\n",
      "loss: 0.304502  [51264/60000]\n",
      "loss: 0.302355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.334616 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.168544  [   64/60000]\n",
      "loss: 0.235656  [ 6464/60000]\n",
      "loss: 0.146952  [12864/60000]\n",
      "loss: 0.236264  [19264/60000]\n",
      "loss: 0.273720  [25664/60000]\n",
      "loss: 0.239867  [32064/60000]\n",
      "loss: 0.215400  [38464/60000]\n",
      "loss: 0.270874  [44864/60000]\n",
      "loss: 0.303553  [51264/60000]\n",
      "loss: 0.301025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.334485 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.168294  [   64/60000]\n",
      "loss: 0.233209  [ 6464/60000]\n",
      "loss: 0.144683  [12864/60000]\n",
      "loss: 0.234836  [19264/60000]\n",
      "loss: 0.271917  [25664/60000]\n",
      "loss: 0.237780  [32064/60000]\n",
      "loss: 0.212919  [38464/60000]\n",
      "loss: 0.267427  [44864/60000]\n",
      "loss: 0.299751  [51264/60000]\n",
      "loss: 0.298914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333853 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.168617  [   64/60000]\n",
      "loss: 0.231619  [ 6464/60000]\n",
      "loss: 0.143733  [12864/60000]\n",
      "loss: 0.231178  [19264/60000]\n",
      "loss: 0.271683  [25664/60000]\n",
      "loss: 0.234497  [32064/60000]\n",
      "loss: 0.210510  [38464/60000]\n",
      "loss: 0.261561  [44864/60000]\n",
      "loss: 0.299487  [51264/60000]\n",
      "loss: 0.299210  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.333463 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.167139  [   64/60000]\n",
      "loss: 0.229312  [ 6464/60000]\n",
      "loss: 0.142857  [12864/60000]\n",
      "loss: 0.228933  [19264/60000]\n",
      "loss: 0.266828  [25664/60000]\n",
      "loss: 0.235552  [32064/60000]\n",
      "loss: 0.208813  [38464/60000]\n",
      "loss: 0.259214  [44864/60000]\n",
      "loss: 0.297774  [51264/60000]\n",
      "loss: 0.296635  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.332650 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.166443  [   64/60000]\n",
      "loss: 0.227215  [ 6464/60000]\n",
      "loss: 0.140519  [12864/60000]\n",
      "loss: 0.225821  [19264/60000]\n",
      "loss: 0.270138  [25664/60000]\n",
      "loss: 0.232288  [32064/60000]\n",
      "loss: 0.206562  [38464/60000]\n",
      "loss: 0.253616  [44864/60000]\n",
      "loss: 0.294910  [51264/60000]\n",
      "loss: 0.296093  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333017 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.167074  [   64/60000]\n",
      "loss: 0.224455  [ 6464/60000]\n",
      "loss: 0.138464  [12864/60000]\n",
      "loss: 0.223325  [19264/60000]\n",
      "loss: 0.268317  [25664/60000]\n",
      "loss: 0.229214  [32064/60000]\n",
      "loss: 0.204040  [38464/60000]\n",
      "loss: 0.253831  [44864/60000]\n",
      "loss: 0.294390  [51264/60000]\n",
      "loss: 0.290893  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.332120 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.166480  [   64/60000]\n",
      "loss: 0.220016  [ 6464/60000]\n",
      "loss: 0.137255  [12864/60000]\n",
      "loss: 0.219974  [19264/60000]\n",
      "loss: 0.268223  [25664/60000]\n",
      "loss: 0.227893  [32064/60000]\n",
      "loss: 0.203056  [38464/60000]\n",
      "loss: 0.245155  [44864/60000]\n",
      "loss: 0.292084  [51264/60000]\n",
      "loss: 0.287397  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.329681 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.160731  [   64/60000]\n",
      "loss: 0.220195  [ 6464/60000]\n",
      "loss: 0.135688  [12864/60000]\n",
      "loss: 0.216643  [19264/60000]\n",
      "loss: 0.267448  [25664/60000]\n",
      "loss: 0.224982  [32064/60000]\n",
      "loss: 0.199434  [38464/60000]\n",
      "loss: 0.242963  [44864/60000]\n",
      "loss: 0.287743  [51264/60000]\n",
      "loss: 0.284768  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.330640 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.164902  [   64/60000]\n",
      "loss: 0.217691  [ 6464/60000]\n",
      "loss: 0.133517  [12864/60000]\n",
      "loss: 0.212514  [19264/60000]\n",
      "loss: 0.265340  [25664/60000]\n",
      "loss: 0.222842  [32064/60000]\n",
      "loss: 0.197902  [38464/60000]\n",
      "loss: 0.239028  [44864/60000]\n",
      "loss: 0.286245  [51264/60000]\n",
      "loss: 0.285571  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.329908 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.160336  [   64/60000]\n",
      "loss: 0.215527  [ 6464/60000]\n",
      "loss: 0.131685  [12864/60000]\n",
      "loss: 0.210838  [19264/60000]\n",
      "loss: 0.263396  [25664/60000]\n",
      "loss: 0.221129  [32064/60000]\n",
      "loss: 0.195963  [38464/60000]\n",
      "loss: 0.236411  [44864/60000]\n",
      "loss: 0.286940  [51264/60000]\n",
      "loss: 0.281853  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329514 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.158371  [   64/60000]\n",
      "loss: 0.213828  [ 6464/60000]\n",
      "loss: 0.130008  [12864/60000]\n",
      "loss: 0.206893  [19264/60000]\n",
      "loss: 0.264303  [25664/60000]\n",
      "loss: 0.218087  [32064/60000]\n",
      "loss: 0.195874  [38464/60000]\n",
      "loss: 0.229705  [44864/60000]\n",
      "loss: 0.284373  [51264/60000]\n",
      "loss: 0.283240  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.329851 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.158013  [   64/60000]\n",
      "loss: 0.210455  [ 6464/60000]\n",
      "loss: 0.127624  [12864/60000]\n",
      "loss: 0.203714  [19264/60000]\n",
      "loss: 0.264936  [25664/60000]\n",
      "loss: 0.216761  [32064/60000]\n",
      "loss: 0.192545  [38464/60000]\n",
      "loss: 0.227043  [44864/60000]\n",
      "loss: 0.282429  [51264/60000]\n",
      "loss: 0.282234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329380 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.157908  [   64/60000]\n",
      "loss: 0.209109  [ 6464/60000]\n",
      "loss: 0.124591  [12864/60000]\n",
      "loss: 0.200809  [19264/60000]\n",
      "loss: 0.263385  [25664/60000]\n",
      "loss: 0.214196  [32064/60000]\n",
      "loss: 0.191663  [38464/60000]\n",
      "loss: 0.222929  [44864/60000]\n",
      "loss: 0.281146  [51264/60000]\n",
      "loss: 0.278595  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328964 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.154247  [   64/60000]\n",
      "loss: 0.206272  [ 6464/60000]\n",
      "loss: 0.124259  [12864/60000]\n",
      "loss: 0.198987  [19264/60000]\n",
      "loss: 0.259100  [25664/60000]\n",
      "loss: 0.212959  [32064/60000]\n",
      "loss: 0.190626  [38464/60000]\n",
      "loss: 0.222803  [44864/60000]\n",
      "loss: 0.280275  [51264/60000]\n",
      "loss: 0.274359  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329815 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.156414  [   64/60000]\n",
      "loss: 0.203655  [ 6464/60000]\n",
      "loss: 0.120529  [12864/60000]\n",
      "loss: 0.198312  [19264/60000]\n",
      "loss: 0.257245  [25664/60000]\n",
      "loss: 0.207595  [32064/60000]\n",
      "loss: 0.190087  [38464/60000]\n",
      "loss: 0.223566  [44864/60000]\n",
      "loss: 0.278006  [51264/60000]\n",
      "loss: 0.271681  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.330575 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.156346  [   64/60000]\n",
      "loss: 0.203560  [ 6464/60000]\n",
      "loss: 0.119288  [12864/60000]\n",
      "loss: 0.193709  [19264/60000]\n",
      "loss: 0.258277  [25664/60000]\n",
      "loss: 0.207293  [32064/60000]\n",
      "loss: 0.185676  [38464/60000]\n",
      "loss: 0.218093  [44864/60000]\n",
      "loss: 0.274869  [51264/60000]\n",
      "loss: 0.269015  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331162 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.155626  [   64/60000]\n",
      "loss: 0.201074  [ 6464/60000]\n",
      "loss: 0.119387  [12864/60000]\n",
      "loss: 0.192165  [19264/60000]\n",
      "loss: 0.257358  [25664/60000]\n",
      "loss: 0.206493  [32064/60000]\n",
      "loss: 0.183626  [38464/60000]\n",
      "loss: 0.216566  [44864/60000]\n",
      "loss: 0.273461  [51264/60000]\n",
      "loss: 0.268244  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331545 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.154443  [   64/60000]\n",
      "loss: 0.198951  [ 6464/60000]\n",
      "loss: 0.116144  [12864/60000]\n",
      "loss: 0.188693  [19264/60000]\n",
      "loss: 0.255991  [25664/60000]\n",
      "loss: 0.205322  [32064/60000]\n",
      "loss: 0.180967  [38464/60000]\n",
      "loss: 0.211903  [44864/60000]\n",
      "loss: 0.272031  [51264/60000]\n",
      "loss: 0.262135  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331166 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.154801  [   64/60000]\n",
      "loss: 0.196610  [ 6464/60000]\n",
      "loss: 0.113559  [12864/60000]\n",
      "loss: 0.188432  [19264/60000]\n",
      "loss: 0.252998  [25664/60000]\n",
      "loss: 0.201965  [32064/60000]\n",
      "loss: 0.177202  [38464/60000]\n",
      "loss: 0.207009  [44864/60000]\n",
      "loss: 0.271519  [51264/60000]\n",
      "loss: 0.261875  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.330872 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.153702  [   64/60000]\n",
      "loss: 0.195891  [ 6464/60000]\n",
      "loss: 0.113137  [12864/60000]\n",
      "loss: 0.183949  [19264/60000]\n",
      "loss: 0.252842  [25664/60000]\n",
      "loss: 0.201929  [32064/60000]\n",
      "loss: 0.176683  [38464/60000]\n",
      "loss: 0.205630  [44864/60000]\n",
      "loss: 0.270062  [51264/60000]\n",
      "loss: 0.261067  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.333139 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.160506  [   64/60000]\n",
      "loss: 0.195904  [ 6464/60000]\n",
      "loss: 0.110886  [12864/60000]\n",
      "loss: 0.181718  [19264/60000]\n",
      "loss: 0.248661  [25664/60000]\n",
      "loss: 0.199695  [32064/60000]\n",
      "loss: 0.175224  [38464/60000]\n",
      "loss: 0.201385  [44864/60000]\n",
      "loss: 0.267836  [51264/60000]\n",
      "loss: 0.255560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.330373 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.151997  [   64/60000]\n",
      "loss: 0.192345  [ 6464/60000]\n",
      "loss: 0.108289  [12864/60000]\n",
      "loss: 0.179047  [19264/60000]\n",
      "loss: 0.249017  [25664/60000]\n",
      "loss: 0.197180  [32064/60000]\n",
      "loss: 0.175825  [38464/60000]\n",
      "loss: 0.200774  [44864/60000]\n",
      "loss: 0.264718  [51264/60000]\n",
      "loss: 0.253249  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.330566 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.150058  [   64/60000]\n",
      "loss: 0.188644  [ 6464/60000]\n",
      "loss: 0.107198  [12864/60000]\n",
      "loss: 0.179032  [19264/60000]\n",
      "loss: 0.249079  [25664/60000]\n",
      "loss: 0.193158  [32064/60000]\n",
      "loss: 0.175090  [38464/60000]\n",
      "loss: 0.198495  [44864/60000]\n",
      "loss: 0.263914  [51264/60000]\n",
      "loss: 0.252824  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.330250 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.147706  [   64/60000]\n",
      "loss: 0.187167  [ 6464/60000]\n",
      "loss: 0.104820  [12864/60000]\n",
      "loss: 0.176489  [19264/60000]\n",
      "loss: 0.247045  [25664/60000]\n",
      "loss: 0.193138  [32064/60000]\n",
      "loss: 0.174209  [38464/60000]\n",
      "loss: 0.193799  [44864/60000]\n",
      "loss: 0.262705  [51264/60000]\n",
      "loss: 0.248763  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.329645 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.147662  [   64/60000]\n",
      "loss: 0.186479  [ 6464/60000]\n",
      "loss: 0.103347  [12864/60000]\n",
      "loss: 0.175818  [19264/60000]\n",
      "loss: 0.245129  [25664/60000]\n",
      "loss: 0.195367  [32064/60000]\n",
      "loss: 0.174278  [38464/60000]\n",
      "loss: 0.191988  [44864/60000]\n",
      "loss: 0.258565  [51264/60000]\n",
      "loss: 0.245644  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.329481 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.142985  [   64/60000]\n",
      "loss: 0.185548  [ 6464/60000]\n",
      "loss: 0.102551  [12864/60000]\n",
      "loss: 0.171978  [19264/60000]\n",
      "loss: 0.241987  [25664/60000]\n",
      "loss: 0.188087  [32064/60000]\n",
      "loss: 0.167404  [38464/60000]\n",
      "loss: 0.190579  [44864/60000]\n",
      "loss: 0.255812  [51264/60000]\n",
      "loss: 0.245528  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.328924 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.140844  [   64/60000]\n",
      "loss: 0.185721  [ 6464/60000]\n",
      "loss: 0.101392  [12864/60000]\n",
      "loss: 0.171784  [19264/60000]\n",
      "loss: 0.239893  [25664/60000]\n",
      "loss: 0.192070  [32064/60000]\n",
      "loss: 0.170692  [38464/60000]\n",
      "loss: 0.188612  [44864/60000]\n",
      "loss: 0.253413  [51264/60000]\n",
      "loss: 0.244394  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.328578 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.138572  [   64/60000]\n",
      "loss: 0.183541  [ 6464/60000]\n",
      "loss: 0.100003  [12864/60000]\n",
      "loss: 0.168769  [19264/60000]\n",
      "loss: 0.240490  [25664/60000]\n",
      "loss: 0.191136  [32064/60000]\n",
      "loss: 0.167388  [38464/60000]\n",
      "loss: 0.190464  [44864/60000]\n",
      "loss: 0.250697  [51264/60000]\n",
      "loss: 0.238303  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.329223 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.142679  [   64/60000]\n",
      "loss: 0.180334  [ 6464/60000]\n",
      "loss: 0.097176  [12864/60000]\n",
      "loss: 0.166850  [19264/60000]\n",
      "loss: 0.235230  [25664/60000]\n",
      "loss: 0.187904  [32064/60000]\n",
      "loss: 0.165411  [38464/60000]\n",
      "loss: 0.185096  [44864/60000]\n",
      "loss: 0.247861  [51264/60000]\n",
      "loss: 0.232895  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.329394 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.135729  [   64/60000]\n",
      "loss: 0.178818  [ 6464/60000]\n",
      "loss: 0.096950  [12864/60000]\n",
      "loss: 0.165063  [19264/60000]\n",
      "loss: 0.234540  [25664/60000]\n",
      "loss: 0.185315  [32064/60000]\n",
      "loss: 0.165678  [38464/60000]\n",
      "loss: 0.183977  [44864/60000]\n",
      "loss: 0.247388  [51264/60000]\n",
      "loss: 0.231303  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.329331 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.134867  [   64/60000]\n",
      "loss: 0.175927  [ 6464/60000]\n",
      "loss: 0.095850  [12864/60000]\n",
      "loss: 0.163687  [19264/60000]\n",
      "loss: 0.232187  [25664/60000]\n",
      "loss: 0.181094  [32064/60000]\n",
      "loss: 0.161760  [38464/60000]\n",
      "loss: 0.180550  [44864/60000]\n",
      "loss: 0.249022  [51264/60000]\n",
      "loss: 0.232633  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.328485 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.132156  [   64/60000]\n",
      "loss: 0.174709  [ 6464/60000]\n",
      "loss: 0.095118  [12864/60000]\n",
      "loss: 0.161050  [19264/60000]\n",
      "loss: 0.235155  [25664/60000]\n",
      "loss: 0.179608  [32064/60000]\n",
      "loss: 0.163819  [38464/60000]\n",
      "loss: 0.175950  [44864/60000]\n",
      "loss: 0.248185  [51264/60000]\n",
      "loss: 0.228274  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.330700 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.132835  [   64/60000]\n",
      "loss: 0.172869  [ 6464/60000]\n",
      "loss: 0.092879  [12864/60000]\n",
      "loss: 0.160166  [19264/60000]\n",
      "loss: 0.227274  [25664/60000]\n",
      "loss: 0.176420  [32064/60000]\n",
      "loss: 0.160814  [38464/60000]\n",
      "loss: 0.172631  [44864/60000]\n",
      "loss: 0.244658  [51264/60000]\n",
      "loss: 0.225191  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.331055 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.128402  [   64/60000]\n",
      "loss: 0.171974  [ 6464/60000]\n",
      "loss: 0.092668  [12864/60000]\n",
      "loss: 0.158629  [19264/60000]\n",
      "loss: 0.225165  [25664/60000]\n",
      "loss: 0.175868  [32064/60000]\n",
      "loss: 0.159389  [38464/60000]\n",
      "loss: 0.171478  [44864/60000]\n",
      "loss: 0.243355  [51264/60000]\n",
      "loss: 0.218010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.331929 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.128614  [   64/60000]\n",
      "loss: 0.170736  [ 6464/60000]\n",
      "loss: 0.090338  [12864/60000]\n",
      "loss: 0.157050  [19264/60000]\n",
      "loss: 0.222642  [25664/60000]\n",
      "loss: 0.172352  [32064/60000]\n",
      "loss: 0.158035  [38464/60000]\n",
      "loss: 0.170848  [44864/60000]\n",
      "loss: 0.242466  [51264/60000]\n",
      "loss: 0.219865  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.330574 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.125123  [   64/60000]\n",
      "loss: 0.168553  [ 6464/60000]\n",
      "loss: 0.088673  [12864/60000]\n",
      "loss: 0.154079  [19264/60000]\n",
      "loss: 0.221430  [25664/60000]\n",
      "loss: 0.173923  [32064/60000]\n",
      "loss: 0.158414  [38464/60000]\n",
      "loss: 0.171252  [44864/60000]\n",
      "loss: 0.240480  [51264/60000]\n",
      "loss: 0.215877  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.331186 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.124819  [   64/60000]\n",
      "loss: 0.167546  [ 6464/60000]\n",
      "loss: 0.089285  [12864/60000]\n",
      "loss: 0.153373  [19264/60000]\n",
      "loss: 0.219860  [25664/60000]\n",
      "loss: 0.172037  [32064/60000]\n",
      "loss: 0.158801  [38464/60000]\n",
      "loss: 0.166443  [44864/60000]\n",
      "loss: 0.237715  [51264/60000]\n",
      "loss: 0.214209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.331361 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.124148  [   64/60000]\n",
      "loss: 0.168986  [ 6464/60000]\n",
      "loss: 0.089711  [12864/60000]\n",
      "loss: 0.151896  [19264/60000]\n",
      "loss: 0.216370  [25664/60000]\n",
      "loss: 0.172393  [32064/60000]\n",
      "loss: 0.157312  [38464/60000]\n",
      "loss: 0.164016  [44864/60000]\n",
      "loss: 0.236817  [51264/60000]\n",
      "loss: 0.214765  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.331839 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.121933  [   64/60000]\n",
      "loss: 0.167704  [ 6464/60000]\n",
      "loss: 0.087546  [12864/60000]\n",
      "loss: 0.147543  [19264/60000]\n",
      "loss: 0.215394  [25664/60000]\n",
      "loss: 0.169376  [32064/60000]\n",
      "loss: 0.155286  [38464/60000]\n",
      "loss: 0.159863  [44864/60000]\n",
      "loss: 0.234413  [51264/60000]\n",
      "loss: 0.206914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.330958 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.117823  [   64/60000]\n",
      "loss: 0.164989  [ 6464/60000]\n",
      "loss: 0.086435  [12864/60000]\n",
      "loss: 0.147438  [19264/60000]\n",
      "loss: 0.211243  [25664/60000]\n",
      "loss: 0.167778  [32064/60000]\n",
      "loss: 0.153939  [38464/60000]\n",
      "loss: 0.156629  [44864/60000]\n",
      "loss: 0.230629  [51264/60000]\n",
      "loss: 0.203005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.331616 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.116343  [   64/60000]\n",
      "loss: 0.164364  [ 6464/60000]\n",
      "loss: 0.084943  [12864/60000]\n",
      "loss: 0.142410  [19264/60000]\n",
      "loss: 0.214882  [25664/60000]\n",
      "loss: 0.167182  [32064/60000]\n",
      "loss: 0.153399  [38464/60000]\n",
      "loss: 0.155403  [44864/60000]\n",
      "loss: 0.226521  [51264/60000]\n",
      "loss: 0.200116  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.332228 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.112840  [   64/60000]\n",
      "loss: 0.162402  [ 6464/60000]\n",
      "loss: 0.082671  [12864/60000]\n",
      "loss: 0.144363  [19264/60000]\n",
      "loss: 0.209973  [25664/60000]\n",
      "loss: 0.163846  [32064/60000]\n",
      "loss: 0.156057  [38464/60000]\n",
      "loss: 0.152514  [44864/60000]\n",
      "loss: 0.224894  [51264/60000]\n",
      "loss: 0.195819  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.332737 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.114033  [   64/60000]\n",
      "loss: 0.160013  [ 6464/60000]\n",
      "loss: 0.081990  [12864/60000]\n",
      "loss: 0.139448  [19264/60000]\n",
      "loss: 0.207019  [25664/60000]\n",
      "loss: 0.159766  [32064/60000]\n",
      "loss: 0.154147  [38464/60000]\n",
      "loss: 0.154590  [44864/60000]\n",
      "loss: 0.220080  [51264/60000]\n",
      "loss: 0.195765  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.333675 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.110441  [   64/60000]\n",
      "loss: 0.159729  [ 6464/60000]\n",
      "loss: 0.081200  [12864/60000]\n",
      "loss: 0.137763  [19264/60000]\n",
      "loss: 0.205436  [25664/60000]\n",
      "loss: 0.160389  [32064/60000]\n",
      "loss: 0.153804  [38464/60000]\n",
      "loss: 0.151102  [44864/60000]\n",
      "loss: 0.218848  [51264/60000]\n",
      "loss: 0.189602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.333990 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.110232  [   64/60000]\n",
      "loss: 0.155763  [ 6464/60000]\n",
      "loss: 0.080289  [12864/60000]\n",
      "loss: 0.135811  [19264/60000]\n",
      "loss: 0.202770  [25664/60000]\n",
      "loss: 0.159456  [32064/60000]\n",
      "loss: 0.151576  [38464/60000]\n",
      "loss: 0.149286  [44864/60000]\n",
      "loss: 0.215614  [51264/60000]\n",
      "loss: 0.187394  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.334117 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.110315  [   64/60000]\n",
      "loss: 0.152685  [ 6464/60000]\n",
      "loss: 0.079639  [12864/60000]\n",
      "loss: 0.133549  [19264/60000]\n",
      "loss: 0.199191  [25664/60000]\n",
      "loss: 0.153476  [32064/60000]\n",
      "loss: 0.152811  [38464/60000]\n",
      "loss: 0.143472  [44864/60000]\n",
      "loss: 0.213253  [51264/60000]\n",
      "loss: 0.185844  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.334863 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.105603  [   64/60000]\n",
      "loss: 0.153237  [ 6464/60000]\n",
      "loss: 0.079034  [12864/60000]\n",
      "loss: 0.130224  [19264/60000]\n",
      "loss: 0.195664  [25664/60000]\n",
      "loss: 0.152076  [32064/60000]\n",
      "loss: 0.150359  [38464/60000]\n",
      "loss: 0.142919  [44864/60000]\n",
      "loss: 0.211537  [51264/60000]\n",
      "loss: 0.188793  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.334772 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.104313  [   64/60000]\n",
      "loss: 0.152006  [ 6464/60000]\n",
      "loss: 0.076556  [12864/60000]\n",
      "loss: 0.128356  [19264/60000]\n",
      "loss: 0.195806  [25664/60000]\n",
      "loss: 0.150808  [32064/60000]\n",
      "loss: 0.150685  [38464/60000]\n",
      "loss: 0.139804  [44864/60000]\n",
      "loss: 0.205904  [51264/60000]\n",
      "loss: 0.186310  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.338005 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.102997  [   64/60000]\n",
      "loss: 0.153256  [ 6464/60000]\n",
      "loss: 0.075119  [12864/60000]\n",
      "loss: 0.127933  [19264/60000]\n",
      "loss: 0.194886  [25664/60000]\n",
      "loss: 0.148309  [32064/60000]\n",
      "loss: 0.148099  [38464/60000]\n",
      "loss: 0.138348  [44864/60000]\n",
      "loss: 0.208803  [51264/60000]\n",
      "loss: 0.182701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.337703 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.100560  [   64/60000]\n",
      "loss: 0.150887  [ 6464/60000]\n",
      "loss: 0.073286  [12864/60000]\n",
      "loss: 0.129525  [19264/60000]\n",
      "loss: 0.191131  [25664/60000]\n",
      "loss: 0.143396  [32064/60000]\n",
      "loss: 0.151162  [38464/60000]\n",
      "loss: 0.137849  [44864/60000]\n",
      "loss: 0.205726  [51264/60000]\n",
      "loss: 0.178801  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.337954 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.098454  [   64/60000]\n",
      "loss: 0.146750  [ 6464/60000]\n",
      "loss: 0.071057  [12864/60000]\n",
      "loss: 0.126216  [19264/60000]\n",
      "loss: 0.186390  [25664/60000]\n",
      "loss: 0.146396  [32064/60000]\n",
      "loss: 0.149569  [38464/60000]\n",
      "loss: 0.132819  [44864/60000]\n",
      "loss: 0.200218  [51264/60000]\n",
      "loss: 0.181439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.339266 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.102923  [   64/60000]\n",
      "loss: 0.145725  [ 6464/60000]\n",
      "loss: 0.072195  [12864/60000]\n",
      "loss: 0.123674  [19264/60000]\n",
      "loss: 0.188441  [25664/60000]\n",
      "loss: 0.144844  [32064/60000]\n",
      "loss: 0.148673  [38464/60000]\n",
      "loss: 0.130570  [44864/60000]\n",
      "loss: 0.199146  [51264/60000]\n",
      "loss: 0.176882  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.339964 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.098073  [   64/60000]\n",
      "loss: 0.140980  [ 6464/60000]\n",
      "loss: 0.071685  [12864/60000]\n",
      "loss: 0.122002  [19264/60000]\n",
      "loss: 0.182462  [25664/60000]\n",
      "loss: 0.135652  [32064/60000]\n",
      "loss: 0.147133  [38464/60000]\n",
      "loss: 0.131957  [44864/60000]\n",
      "loss: 0.196963  [51264/60000]\n",
      "loss: 0.181957  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.340689 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.096937  [   64/60000]\n",
      "loss: 0.139049  [ 6464/60000]\n",
      "loss: 0.071236  [12864/60000]\n",
      "loss: 0.121229  [19264/60000]\n",
      "loss: 0.181289  [25664/60000]\n",
      "loss: 0.142236  [32064/60000]\n",
      "loss: 0.147358  [38464/60000]\n",
      "loss: 0.128364  [44864/60000]\n",
      "loss: 0.198402  [51264/60000]\n",
      "loss: 0.179694  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.340888 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.095079  [   64/60000]\n",
      "loss: 0.138475  [ 6464/60000]\n",
      "loss: 0.072062  [12864/60000]\n",
      "loss: 0.118650  [19264/60000]\n",
      "loss: 0.179102  [25664/60000]\n",
      "loss: 0.133752  [32064/60000]\n",
      "loss: 0.147259  [38464/60000]\n",
      "loss: 0.125095  [44864/60000]\n",
      "loss: 0.194822  [51264/60000]\n",
      "loss: 0.179869  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.342274 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.093941  [   64/60000]\n",
      "loss: 0.137104  [ 6464/60000]\n",
      "loss: 0.067829  [12864/60000]\n",
      "loss: 0.116150  [19264/60000]\n",
      "loss: 0.177854  [25664/60000]\n",
      "loss: 0.131759  [32064/60000]\n",
      "loss: 0.145319  [38464/60000]\n",
      "loss: 0.130133  [44864/60000]\n",
      "loss: 0.193037  [51264/60000]\n",
      "loss: 0.171457  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.342784 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.089659  [   64/60000]\n",
      "loss: 0.134891  [ 6464/60000]\n",
      "loss: 0.071587  [12864/60000]\n",
      "loss: 0.116927  [19264/60000]\n",
      "loss: 0.171906  [25664/60000]\n",
      "loss: 0.132815  [32064/60000]\n",
      "loss: 0.145018  [38464/60000]\n",
      "loss: 0.126894  [44864/60000]\n",
      "loss: 0.190346  [51264/60000]\n",
      "loss: 0.166942  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.344640 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.090553  [   64/60000]\n",
      "loss: 0.133829  [ 6464/60000]\n",
      "loss: 0.068784  [12864/60000]\n",
      "loss: 0.114435  [19264/60000]\n",
      "loss: 0.171961  [25664/60000]\n",
      "loss: 0.133519  [32064/60000]\n",
      "loss: 0.145818  [38464/60000]\n",
      "loss: 0.122985  [44864/60000]\n",
      "loss: 0.187669  [51264/60000]\n",
      "loss: 0.169728  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.345265 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.087735  [   64/60000]\n",
      "loss: 0.131253  [ 6464/60000]\n",
      "loss: 0.066063  [12864/60000]\n",
      "loss: 0.112773  [19264/60000]\n",
      "loss: 0.165552  [25664/60000]\n",
      "loss: 0.132919  [32064/60000]\n",
      "loss: 0.147987  [38464/60000]\n",
      "loss: 0.123460  [44864/60000]\n",
      "loss: 0.184523  [51264/60000]\n",
      "loss: 0.171946  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.345892 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.087250  [   64/60000]\n",
      "loss: 0.129111  [ 6464/60000]\n",
      "loss: 0.068810  [12864/60000]\n",
      "loss: 0.110879  [19264/60000]\n",
      "loss: 0.164037  [25664/60000]\n",
      "loss: 0.129041  [32064/60000]\n",
      "loss: 0.145665  [38464/60000]\n",
      "loss: 0.121326  [44864/60000]\n",
      "loss: 0.184153  [51264/60000]\n",
      "loss: 0.162258  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.346489 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.087473  [   64/60000]\n",
      "loss: 0.128482  [ 6464/60000]\n",
      "loss: 0.065409  [12864/60000]\n",
      "loss: 0.107620  [19264/60000]\n",
      "loss: 0.160572  [25664/60000]\n",
      "loss: 0.131386  [32064/60000]\n",
      "loss: 0.141491  [38464/60000]\n",
      "loss: 0.116550  [44864/60000]\n",
      "loss: 0.178366  [51264/60000]\n",
      "loss: 0.159464  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.347921 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.084036  [   64/60000]\n",
      "loss: 0.126559  [ 6464/60000]\n",
      "loss: 0.065458  [12864/60000]\n",
      "loss: 0.105016  [19264/60000]\n",
      "loss: 0.159022  [25664/60000]\n",
      "loss: 0.126158  [32064/60000]\n",
      "loss: 0.142449  [38464/60000]\n",
      "loss: 0.116524  [44864/60000]\n",
      "loss: 0.178200  [51264/60000]\n",
      "loss: 0.163002  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.348684 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.085894  [   64/60000]\n",
      "loss: 0.124012  [ 6464/60000]\n",
      "loss: 0.065046  [12864/60000]\n",
      "loss: 0.106557  [19264/60000]\n",
      "loss: 0.153973  [25664/60000]\n",
      "loss: 0.125002  [32064/60000]\n",
      "loss: 0.141348  [38464/60000]\n",
      "loss: 0.111710  [44864/60000]\n",
      "loss: 0.175077  [51264/60000]\n",
      "loss: 0.155915  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.350283 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.083872  [   64/60000]\n",
      "loss: 0.125259  [ 6464/60000]\n",
      "loss: 0.065528  [12864/60000]\n",
      "loss: 0.104225  [19264/60000]\n",
      "loss: 0.152901  [25664/60000]\n",
      "loss: 0.127276  [32064/60000]\n",
      "loss: 0.141523  [38464/60000]\n",
      "loss: 0.112477  [44864/60000]\n",
      "loss: 0.168803  [51264/60000]\n",
      "loss: 0.155209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.350079 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.079652  [   64/60000]\n",
      "loss: 0.122400  [ 6464/60000]\n",
      "loss: 0.064915  [12864/60000]\n",
      "loss: 0.102212  [19264/60000]\n",
      "loss: 0.154091  [25664/60000]\n",
      "loss: 0.127741  [32064/60000]\n",
      "loss: 0.143260  [38464/60000]\n",
      "loss: 0.110977  [44864/60000]\n",
      "loss: 0.168228  [51264/60000]\n",
      "loss: 0.153016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.351850 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.078724  [   64/60000]\n",
      "loss: 0.119628  [ 6464/60000]\n",
      "loss: 0.064470  [12864/60000]\n",
      "loss: 0.097677  [19264/60000]\n",
      "loss: 0.156085  [25664/60000]\n",
      "loss: 0.132094  [32064/60000]\n",
      "loss: 0.140695  [38464/60000]\n",
      "loss: 0.108902  [44864/60000]\n",
      "loss: 0.165578  [51264/60000]\n",
      "loss: 0.147224  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.353116 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.080328  [   64/60000]\n",
      "loss: 0.117265  [ 6464/60000]\n",
      "loss: 0.063234  [12864/60000]\n",
      "loss: 0.097361  [19264/60000]\n",
      "loss: 0.147939  [25664/60000]\n",
      "loss: 0.131646  [32064/60000]\n",
      "loss: 0.140417  [38464/60000]\n",
      "loss: 0.099414  [44864/60000]\n",
      "loss: 0.165683  [51264/60000]\n",
      "loss: 0.146416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.354917 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.077792  [   64/60000]\n",
      "loss: 0.116689  [ 6464/60000]\n",
      "loss: 0.063828  [12864/60000]\n",
      "loss: 0.094188  [19264/60000]\n",
      "loss: 0.146459  [25664/60000]\n",
      "loss: 0.125096  [32064/60000]\n",
      "loss: 0.139256  [38464/60000]\n",
      "loss: 0.105766  [44864/60000]\n",
      "loss: 0.163292  [51264/60000]\n",
      "loss: 0.149215  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.355036 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
